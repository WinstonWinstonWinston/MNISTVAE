{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as torch                              # EVEN MORE MATHS :)  \n",
    "import torchvision.datasets as datasets            #\n",
    "from torchvision.transforms import ToTensor \n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "class data(Dataset):\n",
    "    \n",
    "  def __init__(self, X, Y):\n",
    "    self.X = X\n",
    "    self.Y = Y\n",
    "    if len(self.X) != len(self.Y):\n",
    "      raise Exception(\"The length of X does not match the length of Y\")\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # note that this isn't randomly selecting. It's a simple get a single item that represents an x and y\n",
    "    _x = self.X[index]\n",
    "    _y = self.Y[index]\n",
    "\n",
    "    return _x, _y\n",
    "\n",
    "def wav2arr(filename,seconds):\n",
    "    \n",
    "    get_every = 5\n",
    "    \n",
    "    samplerate, data = wavfile.read(filename)\n",
    "    \n",
    "    x = int(samplerate/get_every)\n",
    "    \n",
    "    data = np.sum(data,1)[::get_every]\n",
    "    \n",
    "    totalSamples = int(len(data)/(seconds*x))\n",
    "    \n",
    "    samples = np.zeros((totalSamples,seconds*x))\n",
    "    \n",
    "    for i in range(totalSamples):\n",
    "        samples[i] = data[i*x*seconds:(i+1)*x*seconds]\n",
    "    \n",
    "    return samples/np.max(np.abs(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,117):\n",
    "    insong = \"m4a_files\\\\song\" + str(i) + \".m4a\"\n",
    "    outsong = \"wav_files\\\\song\" + str(i) + \".wav\"\n",
    "    subprocess.run([\"C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\",\"-i\",insong ,outsong],shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: (1780, 141120)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in range(1,117):\n",
    "    X_sub = wav2arr(\"wav_files\\\\song\" + str(i) + \".wav\",16)\n",
    "    Y_sub = torch.ones(len(X_sub))*i\n",
    "    \n",
    "    for j in range(len(X_sub)):\n",
    "        X.append(X_sub[j])\n",
    "        Y.append(Y_sub[j])\n",
    "\n",
    "dataset = data(X,Y)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "print(\"Dataset Size:\", np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()\n",
    "        \n",
    "        # define encoder layers\n",
    "        self.e_dense1 = nn.Linear(141120,2000)\n",
    "        self.e_dense2 = nn.Linear(2000,1000)\n",
    "        self.e_dense3 = nn.Linear(1000,500)\n",
    "        self.e_dense4 = nn.Linear(500, 250)\n",
    "        self.e_dense5 = nn.Linear(250, 100)\n",
    "        self.e_dense6 = nn.Linear(100, 40)\n",
    "        \n",
    "        # define dencoder layers\n",
    "        self.d_dense1 = nn.Linear(20, 100)\n",
    "        self.d_dense2 = nn.Linear(100, 250)\n",
    "        self.d_dense3 = nn.Linear(250, 500)\n",
    "        self.d_dense4 = nn.Linear(500, 1000)\n",
    "        self.d_dense5 = nn.Linear(1000,2000)\n",
    "        self.d_dense6 = nn.Linear(2000,141120)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = torch.tanh(self.e_dense1(x))\n",
    "        x = torch.tanh(self.e_dense2(x))\n",
    "        x = torch.tanh(self.e_dense3(x))\n",
    "        x = torch.tanh(self.e_dense4(x))\n",
    "        x = torch.tanh(self.e_dense5(x))\n",
    "        x = (self.e_dense6(x))\n",
    "        return x[:,:20],x[:,20:]\n",
    "    \n",
    "    def sample(self,μ,log_var):\n",
    "        σ = torch.exp(0.5*log_var)\n",
    "        ϵ = torch.randn_like(σ) # Sample from epsilon\n",
    "        return μ + ϵ.mul(σ),ϵ # transform epsilon into z sample\n",
    "    \n",
    "    def decode(self, x):\n",
    "        x = torch.tanh(self.d_dense1(x))\n",
    "        x = torch.tanh(self.d_dense2(x))\n",
    "        x = torch.tanh(self.d_dense3(x))\n",
    "        x = torch.tanh(self.d_dense4(x))\n",
    "        x = torch.tanh(self.d_dense5(x))\n",
    "        x = torch.tanh(self.d_dense6(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self,x):\n",
    "        μ,log_var = self.encode(x)\n",
    "        z,ϵ = self.sample(μ,log_var)\n",
    "        x = self.decode(z)\n",
    "        return x,μ,log_var,ϵ,z\n",
    "    \n",
    "recon_error = nn.MSELoss(reduction=\"sum\")  # Expectation wrt z of p(x|z)  \n",
    "    \n",
    "def variational_loss(model_x,x,μ,log_var,ϵ,z,epoch):\n",
    "    KL = -0.5 * torch.sum(log_var + 1 - μ.pow(2) - log_var.exp()) # - KL Divergece between standard normal and current p(z) and q(z|x)\n",
    "    if epoch % 10 == 0:\n",
    "        print(KL)\n",
    "        print(recon_error(model_x,x))\n",
    "    return recon_error(model_x,x) + KL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE()\n",
    "optimizer = optim.Adam(vae.parameters(),lr=1e-3/2)\n",
    "criterion = variational_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load(\"model_200\")\n",
    "vae.load_state_dict(state['state_dict'])\n",
    "optimizer.load_state_dict(state['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(),lr=1e-3/2)\n",
    "optimizer.load_state_dict(state['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = variational_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = np.zeros(3001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.5904, grad_fn=<MulBackward0>)\n",
      "tensor(1056443.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.9045, grad_fn=<MulBackward0>)\n",
      "tensor(1115372., grad_fn=<MseLossBackward0>)\n",
      "tensor(45.2858, grad_fn=<MulBackward0>)\n",
      "tensor(1084783.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(52.0345, grad_fn=<MulBackward0>)\n",
      "tensor(1116544.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.9834, grad_fn=<MulBackward0>)\n",
      "tensor(1053855., grad_fn=<MseLossBackward0>)\n",
      "tensor(44.1251, grad_fn=<MulBackward0>)\n",
      "tensor(1103742.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.5593, grad_fn=<MulBackward0>)\n",
      "tensor(1017989.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.2379, grad_fn=<MulBackward0>)\n",
      "tensor(1110695.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.8673, grad_fn=<MulBackward0>)\n",
      "tensor(1113809.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.2454, grad_fn=<MulBackward0>)\n",
      "tensor(1209993.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.3058, grad_fn=<MulBackward0>)\n",
      "tensor(1054354.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.2876, grad_fn=<MulBackward0>)\n",
      "tensor(1121771., grad_fn=<MseLossBackward0>)\n",
      "tensor(44.5849, grad_fn=<MulBackward0>)\n",
      "tensor(1121361., grad_fn=<MseLossBackward0>)\n",
      "tensor(52.3043, grad_fn=<MulBackward0>)\n",
      "tensor(1151675.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.6711, grad_fn=<MulBackward0>)\n",
      "tensor(1078136., grad_fn=<MseLossBackward0>)\n",
      "tensor(52.0954, grad_fn=<MulBackward0>)\n",
      "tensor(1065953.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(54.8770, grad_fn=<MulBackward0>)\n",
      "tensor(1067375.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.0904, grad_fn=<MulBackward0>)\n",
      "tensor(837085.8125, grad_fn=<MseLossBackward0>)\n",
      "====> Epoch: 200 Average loss: 10944.7833\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 201 Average loss: 10936.5846\n",
      "====> Epoch: 202 Average loss: 10934.0127\n",
      "====> Epoch: 203 Average loss: 10928.3217\n",
      "====> Epoch: 204 Average loss: 10913.4033\n",
      "====> Epoch: 205 Average loss: 10901.0125\n",
      "====> Epoch: 206 Average loss: 10893.0063\n",
      "====> Epoch: 207 Average loss: 10885.3867\n",
      "====> Epoch: 208 Average loss: 10865.7189\n",
      "====> Epoch: 209 Average loss: 10846.2058\n",
      "tensor(3060.2185, grad_fn=<MulBackward0>)\n",
      "tensor(1095224.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(2945.8049, grad_fn=<MulBackward0>)\n",
      "tensor(1047739.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3100.3149, grad_fn=<MulBackward0>)\n",
      "tensor(1141033.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(2998.8784, grad_fn=<MulBackward0>)\n",
      "tensor(1031334.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(3080.7166, grad_fn=<MulBackward0>)\n",
      "tensor(1080979.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(2982.7383, grad_fn=<MulBackward0>)\n",
      "tensor(1051690.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(3057.2070, grad_fn=<MulBackward0>)\n",
      "tensor(1169565.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3101.5942, grad_fn=<MulBackward0>)\n",
      "tensor(1098176.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3062.4832, grad_fn=<MulBackward0>)\n",
      "tensor(1143227., grad_fn=<MseLossBackward0>)\n",
      "tensor(3245.3960, grad_fn=<MulBackward0>)\n",
      "tensor(1115527.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(3227.5007, grad_fn=<MulBackward0>)\n",
      "tensor(1037384.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(3135.5112, grad_fn=<MulBackward0>)\n",
      "tensor(1043870.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(3227.9453, grad_fn=<MulBackward0>)\n",
      "tensor(1083453.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3246.3293, grad_fn=<MulBackward0>)\n",
      "tensor(1088441.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3235.1558, grad_fn=<MulBackward0>)\n",
      "tensor(978575.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(3166.8855, grad_fn=<MulBackward0>)\n",
      "tensor(1042203., grad_fn=<MseLossBackward0>)\n",
      "tensor(3173.2109, grad_fn=<MulBackward0>)\n",
      "tensor(1110595.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(2554.1362, grad_fn=<MulBackward0>)\n",
      "tensor(839423.7500, grad_fn=<MseLossBackward0>)\n",
      "====> Epoch: 210 Average loss: 10816.8817\n",
      "====> Epoch: 211 Average loss: 10817.6272\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-485204930742>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mmodel_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mμ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mϵ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mμ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mϵ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-73fb39c391a4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mμ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mϵ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mμ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mμ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mϵ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-73fb39c391a4>\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_dense4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_dense5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_dense6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(200,3001):  # loop over the dataset multiple times\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for i, indata in enumerate(train_loader,start = 1):\n",
    "        \n",
    "        inputs = indata[0].float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        model_x,μ,log_var,ϵ,z = vae(inputs)\n",
    "        loss = criterion(model_x,inputs,μ,log_var,ϵ,z,epoch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(inputs), len(train_loader.dataset),\n",
    "                (100*(len(inputs) * i) / len(train_loader.dataset)), loss.item() / len(inputs)))\n",
    "    \n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, total_loss / len(train_loader.dataset)))\n",
    "    \n",
    "    LOSS[epoch] =  total_loss / len(train_loader.dataset)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        plt.plot(LOSS[107:epoch])\n",
    "        plt.title(\"LOSS\")\n",
    "        plt.show()\n",
    "        state = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': vae.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "                }\n",
    "        torch.save(state, \"model_\" + str(epoch) )\n",
    "    \n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
